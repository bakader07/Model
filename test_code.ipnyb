{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "from optuna import Trial\n",
    "from keras.backend import clear_session\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential\n",
    "from livelossplot import PlotLossesKeras\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\"def read_data(data_dir):\n",
    "    # Implement logic to read image paths and labels from data_dir\n",
    "    images = []\n",
    "    labels = []\n",
    "    # ... (your data reading code)\n",
    "    return images, labels\n",
    "\"\"\"\n",
    "#study_name = 'cell_images' + '_Simple'\n",
    "#ok = optuna(study_name=study_name)\n",
    "def objective(trial):\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "    #def train_model(trial,data, labels):\n",
    "    # Load pre-trained VGG19 with frozen layers\n",
    "    # Import data \n",
    "    infected_path = \"C:/Users/Dell/Downloads/cell_images/Parasitized/\"\n",
    "    uninfected_path = \"C:/Users/Dell/Downloads/cell_images/Uninfected/\"\n",
    "    infected_files = os.listdir(infected_path)\n",
    "\n",
    "    uninfected_files = os.listdir(uninfected_path)\n",
    "\n",
    "    # Define functions for data preprocessing\n",
    "    def preprocess_data(file_list, label):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for file in file_list:\n",
    "            try:\n",
    "                image = tf.keras.preprocessing.image.load_img(file, target_size=(100, 100))\n",
    "                image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "                data.append(image_array)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "        return data, labels\n",
    "\n",
    "    # Preprocess infected and uninfected data\n",
    "    infected_data, infected_labels = preprocess_data([os.path.join(infected_path, f) for f in infected_files], 1)\n",
    "    uninfected_data, uninfected_labels = preprocess_data([os.path.join(uninfected_path, f) for f in uninfected_files], 0)\n",
    "\n",
    "    # Combine data and labels\n",
    "    data = np.array(infected_data + uninfected_data)\n",
    "    labels = np.array(infected_labels + uninfected_labels)\n",
    "    print(len(data))\n",
    "    data = data / 255.0\n",
    "\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    \n",
    "    def kfold_indices(data, k):\n",
    "        fold_size = len(data) // k\n",
    "        indices = np.arange(len(data))\n",
    "        folds = []\n",
    "        for i in range(k):\n",
    "            test_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "            train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
    "            folds.append((train_indices, test_indices))\n",
    "        return folds\n",
    "\n",
    "    # Define the number of folds (K)\n",
    "    #k = 5\n",
    "\n",
    "    # Get the fold indices\n",
    "    #fold_indices = kfold_indices(data, k)\n",
    "    #print(fold_indices[0])\n",
    "    #base_model = VGG19(weights=\"imagenet\", include_top=False)\n",
    "    #for layer in base_model.layers:\n",
    "    #layer.trainable = False\n",
    "\n",
    "    \"\"\"\n",
    "    tf.keras.layers.Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),\n",
    "            input_shape=(100, 100, 3)),\n",
    "    tf.keras.layers.Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),),\n",
    "    tf.keras.layers.Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(2000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "    \"\"\"\n",
    "    #base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Sequential()\n",
    "    # Layer 1\n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),\n",
    "            input_shape=(100, 100, 3)),\n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),)\n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),),\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Layer 2\n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),\n",
    "            input_shape=(100, 100, 3)),\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Layer 3\n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),\n",
    "            input_shape=(100, 100, 3)),\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())  \n",
    "    \n",
    "    # Add 2 final dense layers to add a classifier to the convolutional base\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \"\"\"model = tf.keras.Sequential([\n",
    "    \n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),\n",
    "            input_shape=(100, 100, 3)),\n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),),    \n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),), \n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dense(2, activation='softmax')])\"\"\"\n",
    "    #model.add(base_model)\n",
    "    #model.add(Flatten())\n",
    "    #model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \"\"\"model.add(\n",
    "        Conv2D(\n",
    "            filters=trial.suggest_categorical(\"filters\", [32, 128]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),\n",
    "        )\n",
    "    )\"\"\"\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    #learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    # Compile with Optuna-suggested optimizer and BinaryFocalCrossentropy loss\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=trial.suggest_float(\"lr\", 1e-5, 1e-3)),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # KFold cross-validation\n",
    "    #kfold = KFold(n_splits=5, shuffle=True)  # Adjust n_splits as needed\n",
    "    best_val_acc = 0\n",
    "    BATCHSIZE = 16\n",
    "    \n",
    "    kFold=KFold(n_splits=5,shuffle=True)\n",
    "    callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    verbose=0,\n",
    "    )\n",
    "    check=keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"C:/Users/Dell/Downloads/project_files/best.h5\",\n",
    "    monitor=\"val_acc\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    )\n",
    "    m=[]\n",
    "    h=[]\n",
    "    for train_indices, test_indices in kFold.split(data):\n",
    "        #X_train, y_train = data[train_indices], labels[train_indices]\n",
    "        #X_test, y_test = data[test_indices], labels[test_indices]\n",
    "        X_train, X_test, y_train, y_test = data[train_indices], data[test_indices], labels[train_indices], labels[test_indices]\n",
    "\n",
    "        #datagen.fit(X_train)\n",
    "        # fits the model on batches with real-time data augmentation:\n",
    "        \"\"\"history = model.fit(X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            steps_per_epoch=len(X_train) / 32,\n",
    "            shuffle=True,\n",
    "            batch_size=BATCHSIZE,\n",
    "            epochs=EPOCHS,\n",
    "            verbose=False)\"\"\"\n",
    "        train_datagen = datagen.flow(X_train, y_train, batch_size=32)\n",
    "        test_datagen = datagen.flow(X_train, y_train, batch_size=32)\n",
    "        history = model.fit(train_datagen,batch_size=BATCHSIZE, epochs=100, validation_data=(test_datagen),callbacks=[callback,PlotLossesKeras(),check])\n",
    "        m.append(model)\n",
    "        h.append(history)\n",
    "        np.savetxt(\"C:/Users/Dell/Downloads/project_files/h.txt\", h, delimiter=\",\")\n",
    "        np.savetxt(\"C:/Users/Dell/Downloads/project_files/m.txt\", m, delimiter=\",\")\n",
    "        # Evaluate and track best model\n",
    "        val_acc = history.history[\"val_accuracy\"][-1]\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            model.save_weights(\"C:/Users/Dell/Downloads/project_files/best_malaria_model.h5\")  # Save best weights\n",
    "    \n",
    "    \"\"\"plt.figure(figsize=(5, 5))\n",
    "    for fold_i, fold_history in enumerate(history):\n",
    "        plt.plot(fold_history[\"accuracy\"], label=f\"Fold {fold_i+1} Train Acc\")\n",
    "        plt.plot(fold_history[\"val_accuracy\"], label=f\"Fold {fold_i+1} Val Acc\")\n",
    "        plt.plot(fold_history[\"loss\"], label=f\"Fold {fold_i+1} Train Loss\")\n",
    "        plt.plot(fold_history[\"val_loss\"], label=f\"Fold {fold_i+1} Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy/Loss\")\n",
    "    plt.title(\"Training and Validation Metrics (KFold)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\"\"\"\n",
    "    return -best_val_acc  # Return negative validation accuracy for Optuna minimization\n",
    "\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Optimize hyperparameters\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Access the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "\n",
    "# Load best model weights\n",
    "#model.load_weights(\"/Users/fadiabaissi/Desktop/Bureau/projet files/best_malaria_model.h5\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
